{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling and Analysis\n",
    "\n",
    "This Notebook will model the data and gather insights. This will include:\n",
    "- Data Cleaning\n",
    "- Data Exploration\n",
    "- Data Visualization\n",
    "- Conclusions\n",
    "\n",
    "All of the above will be done in order to answer the following questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "\n",
    "## Sklearn \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## NLTK\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Ignore warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2142, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>ups</th>\n",
       "      <th>score</th>\n",
       "      <th>edited</th>\n",
       "      <th>is_self</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_self.USMC</th>\n",
       "      <th>domain_self.army</th>\n",
       "      <th>domain_self.bipolar</th>\n",
       "      <th>domain_self.schizophrenia</th>\n",
       "      <th>domain_stripes.com</th>\n",
       "      <th>domain_v.redd.it</th>\n",
       "      <th>domain_youtu.be</th>\n",
       "      <th>domain_youtube.com</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Army</td>\n",
       "      <td>This was a convo I had with one of my buddies ...</td>\n",
       "      <td>If you could create a new MRE based on a Fast ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/army</td>\n",
       "      <td>0.706224</td>\n",
       "      <td>-0.274788</td>\n",
       "      <td>-0.274788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army</td>\n",
       "      <td>BLUF: how do you overcome imposter syndrome?\\n...</td>\n",
       "      <td>how do you even Army?</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/army</td>\n",
       "      <td>-1.548767</td>\n",
       "      <td>-0.299627</td>\n",
       "      <td>-0.299627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Army</td>\n",
       "      <td>Long story short, my estranged (soon to be ex)...</td>\n",
       "      <td>Command Directed No-Contact Order?</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/army</td>\n",
       "      <td>0.706224</td>\n",
       "      <td>-0.287207</td>\n",
       "      <td>-0.287207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Army</td>\n",
       "      <td>\\nMy husband is 35T, and just graduated AIT. W...</td>\n",
       "      <td>Anyone 35T?</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/army</td>\n",
       "      <td>-0.132842</td>\n",
       "      <td>-0.262368</td>\n",
       "      <td>-0.262368</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Army</td>\n",
       "      <td>I could use some advice on going recruiting. I...</td>\n",
       "      <td>Thinking of going recruiter as brand new E5</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/army</td>\n",
       "      <td>0.706224</td>\n",
       "      <td>-0.287207</td>\n",
       "      <td>-0.287207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                           selftext  \\\n",
       "0      Army  This was a convo I had with one of my buddies ...   \n",
       "1      Army  BLUF: how do you overcome imposter syndrome?\\n...   \n",
       "2      Army  Long story short, my estranged (soon to be ex)...   \n",
       "3      Army  \\nMy husband is 35T, and just graduated AIT. W...   \n",
       "4      Army  I could use some advice on going recruiting. I...   \n",
       "\n",
       "                                               title link_flair_richtext  \\\n",
       "0  If you could create a new MRE based on a Fast ...                  []   \n",
       "1                              how do you even Army?                  []   \n",
       "2                 Command Directed No-Contact Order?                  []   \n",
       "3                                        Anyone 35T?                  []   \n",
       "4        Thinking of going recruiter as brand new E5                  []   \n",
       "\n",
       "  subreddit_name_prefixed  upvote_ratio       ups     score  edited  is_self  \\\n",
       "0                  r/army      0.706224 -0.274788 -0.274788       0        1   \n",
       "1                  r/army     -1.548767 -0.299627 -0.299627       0        1   \n",
       "2                  r/army      0.706224 -0.287207 -0.287207       0        1   \n",
       "3                  r/army     -0.132842 -0.262368 -0.262368       0        1   \n",
       "4                  r/army      0.706224 -0.287207 -0.287207       0        1   \n",
       "\n",
       "   ...  domain_self.USMC  domain_self.army  domain_self.bipolar  \\\n",
       "0  ...                 0                 1                    0   \n",
       "1  ...                 0                 1                    0   \n",
       "2  ...                 0                 1                    0   \n",
       "3  ...                 0                 1                    0   \n",
       "4  ...                 0                 1                    0   \n",
       "\n",
       "  domain_self.schizophrenia  domain_stripes.com  domain_v.redd.it  \\\n",
       "0                         0                   0                 0   \n",
       "1                         0                   0                 0   \n",
       "2                         0                   0                 0   \n",
       "3                         0                   0                 0   \n",
       "4                         0                   0                 0   \n",
       "\n",
       "   domain_youtu.be  domain_youtube.com  hour_of_day  day_of_week  \n",
       "0                0                   0           23            5  \n",
       "1                0                   0           23            5  \n",
       "2                0                   0           23            5  \n",
       "3                0                   0           22            5  \n",
       "4                0                   0           22            5  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../3_ANALYSIS/data/processed_data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kyerafrancis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kyerafrancis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    '''\n",
    "    This function is performing text cleaning in order to prepare the text for NLP analysis.\n",
    "    This includes:\n",
    "    - Lowercasing\n",
    "    - Removing special characters and digits\n",
    "    - Tokenizing into words\n",
    "    - Removing stopwords\n",
    "    - Lemmatization\n",
    "    \n",
    "    Returns: Cleaned text\n",
    "    \n",
    "    '''\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "    # Tokenize into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_nlp(df, text_column='selftext', target_column='subreddit'):\n",
    "    ''' \n",
    "    This function is performing text preprocessing and vectorization for NLP analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: dataframe\n",
    "    - text_column: column containing text data\n",
    "    - target_column: column containing target variable\n",
    "    \n",
    "    \n",
    "    Returns: X_train_vect, X_test_vect, y_train, y_test, vectorizer\n",
    "    '''\n",
    "    # Preprocess text data\n",
    "    df[text_column] = df[text_column].apply(lambda x: preprocess_text(str(x)))\n",
    "\n",
    "    # Split dataset into features and target variable\n",
    "    X = df[text_column]\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Vectorization - using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "    return X_train_vect, X_test_vect, y_train, y_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, vectorizer = prepare_data_for_nlp(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
